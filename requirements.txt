#scikit-learn==1.4.1.post1
scipy==1.12.0
nltk==3.8.1
contractions==0.1.73
gensim==4.3.2
#torch==2.2.1
requests==2.31.0
numpy==1.26.4
matplotlib==3.8.3
pandas==2.2.0
transformers==4.38.1
sentence_transformers==2.7.0
langchain_community==0.0.34
langchain==0.1.16
chromadb==0.4.24
llama_cpp_python==0.2.63
pypdf==4.2.0
Flask==3.0.3
googletrans==4.0.0rc1
# nltk.download('stopwords')
# nltk.download('punkt')
# nltk.download('wordnet')
# sudo apt install unzip

# The following is for using GPU in llm_call
#pip uninstall llama-cpp-python
#set LLAMA_CUBLAS="1"
#set FORCE_CMAKE="1"
#set CMAKE_ARGS="-DLLAMA_CUBLAS=on"
#pip install llama-cpp-python --prefer-binary --extra-index-#url=https://jllllll.github.io/llama-cpp-python-cuBLAS-wheels/AVX2/cu122
